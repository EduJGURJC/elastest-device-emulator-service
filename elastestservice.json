{
  "register": {
    // Request body of "register" ESM operation...
    "description": "this is a test service for ElasTest Device Emulator Service",
    "id": "3514e8ea-8d6c-11e7-bb31-be2e44b06b34",
    "name": "ElasTest Device Emulator Service",
    "bindable": false,
    "plan_updateable": false,
    "plans": [
      {
        "bindable": false,
        "description": "plan for testing",
        "free": true,
        "id": "3514e8ea-8d6c-11e7-bb31-be2e44b06b34",
        "metadata": {
          "bullets": "basic plan",
          "costs": {
            "components": {},
            "description": "On Demand 5 per deployment, 50 per core, 10 per GB ram and 1 per GB disk",
            "fix_cost": {
              "deployment": 5
            },
            "name": "On Demand 5 + Charges",
            "type": "ONDEMAND",
            "var_rate": {
              "cpus": 50,
              "disk": 1,
              "memory": 10
            }
          }
        },
        "name": "testing plan"
      }
    ],
    "requires": [],
    "tags": [
      "test",
      "tester"
    ]
  },
  "manifest": {
    "id": "f178ae1c-8d6d-11e7-bb31-be2e44b06b34",
    "manifest_content": "version: '2'</br></br>services:</br>  eds-frontend:</br>   eds-memsipe:</br>  eds-zigbeeipe:</br>    image: elastest/eds-frontend</br>  image: elastest/eds-memsipe</br>    image: elastest/eds-zigbeeipe</br>  container_name: spark-master</br>    ports:</br>      - \"8080:8080\"</br>    volumes:</br>      - ./spark/alluxio_conf:/opt/alluxio/conf</br>      - ./spark/spark_conf:/opt/spark/conf</br>      - ./spark/hadoop_conf:/usr/local/hadoop/etc/hadoop</br>    command: [\"/usr/bin/supervisord\", \"--configuration=/opt/conf/master.conf\"]</br>    hostname: spark-master</br>    networks:</br>      - elastest</br></br>  spark-worker:</br>    image: elastest/ebs-spark-base:0.5.0</br>    depends_on:</br>      - spark-master</br>    ports:</br>      - \"8081\"</br>    volumes:</br>      - ./spark/alluxio_conf:/opt/alluxio/conf</br>      - ./spark/spark_conf:/opt/spark/conf</br>      - ./spark/hadoop_conf:/usr/local/hadoop/etc/hadoop</br>    command: [\"/usr/bin/supervisord\", \"--configuration=/opt/conf/slave.conf\"]</br>    hostname: spark-worker</br>    networks:</br>      - elastest</br></br>networks:</br>  elastest:</br>    external: true</br>",
    "manifest_type": "dummy",
    "plan_id": "testplan",
    "service_id": "test-svc"
  }
}